compute_environment: COLAB_GPU          # Use GPU, as Colab typically provides GPUs
debug: false
deepspeed_config:
  deepspeed_multinode_launcher: standard
  offload_optimizer_device: none
  offload_param_device: none
  zero3_init_flag: true
  zero3_save_16bit_model: true
  zero_stage: 3
distributed_type: DEEPSPEED             # Still using DeepSpeed, even though it's unlikely to require multiple machines in Colab
downcast_bf16: 'no'
machine_rank: 0                          # Single machine, so machine rank is 0
main_training_function: main
mixed_precision: bf16                    # Using bf16 for mixed precision training, supported on Colab's GPUs (e.g., A100)
num_machines: 1                          # Only one machine in Colab
num_processes: 1                         # Typically 1 process in Colab, unless using data parallelism
rdzv_backend: static
same_network: true
tpu_env: []                              # No TPU usage in Colab (unless you're using a specific Colab TPU environment)
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false                           # Use GPU, not CPU
